{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w1MUVtZ4B73"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import words\n",
        "\n",
        "# === Downloads ===\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')\n",
        "\n",
        "# === Common Folder Path ===\n",
        "FOLDER_PATH = \"/content/data/txt\"\n",
        "\n",
        "# -------------------------------\n",
        "#  PART 1: Missing Abbreviation Definitions\n",
        "# -------------------------------\n",
        "\n",
        "OUTPUT_CSV_MISSING = \"missing_abbreviation_definitions.csv\"\n",
        "\n",
        "ABBREV_PATTERN = re.compile(r\"\\b[A-Z]{2,6}\\b\")  # abbreviation length >=2 and <=6\n",
        "DEFINED_ABBREV_PATTERN = re.compile(r\"\\b([A-Za-z][A-Za-z\\s\\-]+)\\s*\\(([A-Z]{2,6})\\)\")\n",
        "DEFINED_REVERSE_PATTERN = re.compile(r\"\\b([A-Z]{2,6})\\s*\\(([A-Za-z][A-Za-z\\s\\-]+)\\)\")\n",
        "\n",
        "COMMON_ABBREVS = {\"UI\", \"API\", \"DB\", \"RAM\", \"CPU\", \"SQL\", \"HTTP\", \"HTTPS\",\n",
        "                  \"ID\", \"OS\", \"URL\", \"JSON\", \"XML\", \"GUI\", \"IP\", \"FTP\", \"DNS\"}\n",
        "\n",
        "REAL_WORDS = set(w.lower() for w in words.words())\n",
        "\n",
        "def preprocess_text_missing(text):\n",
        "    \"\"\"Clean and normalize SRS text before NLP processing.\"\"\"\n",
        "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \" \", text)\n",
        "    text = re.sub(r\"(\\w)-\\s*\\n\\s*(\\w)\", r\"\\1\\2\", text)\n",
        "    text = text.replace(\"\\r\", \" \").replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
        "    text = re.sub(r\"\\bPage\\s*\\d+(\\s*of\\s*\\d+)?\\b\", \" \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"\\bConfidential\\b\", \" \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'^[A-Z\\s\\d\\.\\-]{3,}$', ' ', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r\"\\d+(\\.\\d+)*\\s+[A-Z][A-Z\\s]+\", \" \", text)\n",
        "    srs_junk = [\n",
        "        \"figure\", \"table\", \"document\", \"revision\", \"purpose\",\n",
        "        \"scope\", \"requirement\", \"module\", \"version\", \"description\"\n",
        "    ]\n",
        "    for word in srs_junk:\n",
        "        text = re.sub(rf\"\\b{word}\\b\", \" \", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "rows_missing = []\n",
        "\n",
        "for filename in os.listdir(FOLDER_PATH):\n",
        "    if not filename.endswith(\".txt\"):\n",
        "        continue\n",
        "\n",
        "    filepath = os.path.join(FOLDER_PATH, filename)\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
        "        raw_text = file.readlines()\n",
        "\n",
        "    text = \"\".join(raw_text[50:])  # Skip metadata\n",
        "    text = preprocess_text_missing(text)\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    defined_abbrevs = set()\n",
        "    for full, abbr in re.findall(DEFINED_ABBREV_PATTERN, text):\n",
        "        defined_abbrevs.add(abbr.strip())\n",
        "    for abbr, full in re.findall(DEFINED_REVERSE_PATTERN, text):\n",
        "        defined_abbrevs.add(abbr.strip())\n",
        "\n",
        "    all_abbrevs = set(re.findall(ABBREV_PATTERN, text))\n",
        "    missing_abbrevs = (all_abbrevs - defined_abbrevs) - COMMON_ABBREVS\n",
        "    missing_abbrevs = {abbr for abbr in missing_abbrevs if abbr.lower() not in REAL_WORDS}\n",
        "\n",
        "    found_abbrevs = set()\n",
        "\n",
        "    for sent in sentences:\n",
        "        letters = re.findall(r'[A-Za-z]', sent)\n",
        "        if letters and sum(1 for c in letters if c.isupper()) / len(letters) > 0.7:\n",
        "            continue\n",
        "        if len(sent.split()) < 5:\n",
        "            continue\n",
        "        if len(re.findall(r'\\b[A-Z]{2,6}\\b', sent)) >= 5:\n",
        "            continue\n",
        "        if re.search(r'\\b(19|20)\\d{2}\\b', sent) or re.search(\n",
        "            r'\\d{1,2}[-/](JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEC)',\n",
        "            sent, re.IGNORECASE):\n",
        "            continue\n",
        "        if re.findall(r'[A-Z]\\.\\s*[A-Z][a-z]+', sent):\n",
        "            continue\n",
        "\n",
        "        for abbr in list(missing_abbrevs):\n",
        "            if abbr not in found_abbrevs and re.search(rf\"\\b{abbr}\\b\", sent):\n",
        "                rows_missing.append({\n",
        "                    \"File\": filename,\n",
        "                    \"Abbreviation\": abbr,\n",
        "                    \"Type of Bad Smell\": \"Missing Abbreviation Definition\",\n",
        "                    \"Sentence\": sent.strip()\n",
        "                })\n",
        "                found_abbrevs.add(abbr)\n",
        "\n",
        "df_missing = pd.DataFrame(rows_missing)\n",
        "df_missing.to_csv(OUTPUT_CSV_MISSING, index=False)\n",
        "print(f\"‚úÖ Done! Found {len(df_missing)} missing abbreviation definitions.\")\n",
        "print(f\"üìÑ Output saved to {OUTPUT_CSV_MISSING}\")\n",
        "\n",
        "# -------------------------------\n",
        "#  PART 2: Inconsistent Abbreviation Usage\n",
        "# -------------------------------\n",
        "\n",
        "OUTPUT_CSV_INCONSISTENT = \"abbreviation_inconsistencies.csv\"\n",
        "\n",
        "DEFINED_ABBREV_PATTERN_INC = re.compile(r\"\\b([A-Za-z][A-Za-z\\s\\-]+?)\\s*\\(([A-Z]{2,6})\\)\")\n",
        "DEFINED_REVERSE_PATTERN_INC = re.compile(r\"\\b([A-Z]{2,6})\\s*\\(([A-Za-z][A-Za-z\\s\\-]+?)\\)\")\n",
        "\n",
        "BAD_STARTERS = {\"for\", \"in\", \"on\", \"at\", \"by\", \"to\", \"from\", \"and\", \"or\", \"if\", \"with\", \"this\", \"that\", \"these\", \"those\"}\n",
        "\n",
        "def preprocess_text_inconsistency(text):\n",
        "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \" \", text)\n",
        "    text = re.sub(r\"(\\w)-\\s*\\n\\s*(\\w)\", r\"\\1\\2\", text)\n",
        "    text = text.replace(\"\\r\", \" \").replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "def is_valid_full_form(full):\n",
        "    words_ = full.strip().split()\n",
        "    if len(words_) < 2 or len(words_) > 6:\n",
        "        return False\n",
        "    if words_[0].lower() in BAD_STARTERS:\n",
        "        return False\n",
        "    if not any(w[0].isupper() for w in words_ if w.isalpha()):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "rows_inconsistency = []\n",
        "term_to_abbrs = {}\n",
        "\n",
        "for filename in os.listdir(FOLDER_PATH):\n",
        "    if not filename.endswith(\".txt\"):\n",
        "        continue\n",
        "\n",
        "    filepath = os.path.join(FOLDER_PATH, filename)\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
        "        raw_text = file.read()\n",
        "\n",
        "    text = preprocess_text_inconsistency(raw_text)\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    for full, abbr in re.findall(DEFINED_ABBREV_PATTERN_INC, text):\n",
        "        full_clean = full.strip()\n",
        "        abbr_clean = abbr.strip()\n",
        "        if len(abbr_clean) >= 2 and len(abbr_clean) <= 6 and is_valid_full_form(full_clean):\n",
        "            term_to_abbrs.setdefault(full_clean, set()).add(abbr_clean)\n",
        "\n",
        "    for abbr, full in re.findall(DEFINED_REVERSE_PATTERN_INC, text):\n",
        "        full_clean = full.strip()\n",
        "        abbr_clean = abbr.strip()\n",
        "        if len(abbr_clean) >= 2 and len(abbr_clean) <= 6 and is_valid_full_form(full_clean):\n",
        "            term_to_abbrs.setdefault(full_clean, set()).add(abbr_clean)\n",
        "\n",
        "for term, abbrs in term_to_abbrs.items():\n",
        "    if len(abbrs) > 1:\n",
        "        rows_inconsistency.append({\n",
        "            \"Full Form\": term,\n",
        "            \"Abbreviations\": \", \".join(sorted(list(abbrs))),\n",
        "            \"Type of Bad Smell\": \"Inconsistent Abbreviation Usage\"\n",
        "        })\n",
        "\n",
        "df_inconsistency = pd.DataFrame(rows_inconsistency)\n",
        "df_inconsistency.to_csv(OUTPUT_CSV_INCONSISTENT, index=False)\n",
        "print(f\"‚úÖ Done! Found {len(df_inconsistency)} inconsistent abbreviation definitions.\")\n",
        "print(f\"üìÑ Output saved to {OUTPUT_CSV_INCONSISTENT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "#  PART 1B: Get Expected Abbreviation Definitions using Bard AI\n",
        "# ========================================\n",
        "from bardapi import Bard\n",
        "import time\n",
        "\n",
        "# Load Bard API Key (required for bardapi)\n",
        "os.environ['_BARD_API_KEY'] = \"YOUR_BARD_API_KEY_HERE\"  # replace this with your actual key\n",
        "\n",
        "# Reuse the missing abbreviations DataFrame\n",
        "if not df_missing.empty:\n",
        "    print(\" Querying Bard AI for expected meanings of abbreviations...\")\n",
        "\n",
        "    bard = Bard()  # Initialize Bard client\n",
        "    suggested_defs = []\n",
        "\n",
        "    for i, row in df_missing.iterrows():\n",
        "        abbr = row[\"Abbreviation\"]\n",
        "        prompt = f\"What is the most common full form of the abbreviation '{abbr}' in software or technical context?\"\n",
        "        try:\n",
        "            response = bard.get_answer(prompt)\n",
        "            meaning = response.get(\"content\", \"\").strip()\n",
        "            # Clean possible Bard extra text\n",
        "            meaning = meaning.split(\"\\n\")[0].replace(\"**\", \"\").replace(\"*\", \"\")\n",
        "        except Exception as e:\n",
        "            meaning = f\"Error: {str(e)}\"\n",
        "\n",
        "        suggested_defs.append(meaning)\n",
        "        print(f\"‚úÖ {abbr} ‚Üí {meaning}\")\n",
        "        time.sleep(2)  # delay to avoid hitting request limits\n",
        "\n",
        "    # Add new column\n",
        "    df_missing[\"Suggested Definition\"] = suggested_defs\n",
        "\n",
        "    # Save updated CSV\n",
        "    df_missing.to_csv(\"missing_abbreviation_definitions_with_bard.csv\", index=False)\n",
        "    print(\"\\nüìÑ Output with Bard suggestions saved to 'missing_abbreviation_definitions_with_bard.csv'\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No missing abbreviations found ‚Äî skipping Bard lookup.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
